{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 30px;\">\n",
    "    <strong>\n",
    "          Scraper para reseñas de productos Amazon.es\n",
    "    </strong>\n",
    "</p>\n",
    "\n",
    "----\n",
    "\n",
    "<b style=\"text-align: left; font-size: 18px;\">\n",
    "    El siguiente proyecto se ha diseñado  para obtener datos públicos sobre las opiniones de los usuarios sobre productos de amazon.es.\n",
    "</b>\n",
    "\n",
    "----\n",
    "\n",
    "<b style=\"font-size: 20px;\">Plan del proyecto</b>\n",
    "\n",
    "-  <p style=\"font-size: 18px;\">Crear la lista de los URLs</p>\n",
    "-  <p style=\"font-size: 18px;\">Desarrollar un programa para acceder automáticamente a sitios web especificados y extraer sus datos</p>\n",
    "-  <p style=\"font-size: 18px;\">Guardar los datos adquiridos en una base de datos para posterior procesamiento</p>\n",
    "---\n",
    "\n",
    "<b style=\"font-size: 20px;\">Herramientas</b>\n",
    "\n",
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    <a href=\"https://www.python.org/downloads/\" target=\"_blank\" rel=\"noopener noreferrer\">Última versión de Python</a>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    <a href=\"https://googlechromelabs.github.io/chrome-for-testing/\" target=\"_blank\" rel=\"noopener noreferrer\">Última versión de WebDriver</a>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    Biblioteca Selenuim para tareas scraping\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    Biblioteca Pandas para almacenar y manipular los datos\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    Biblioteca TQDM para visualizar el progreso\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b style=\"font-size: 20px;\">Importaciones necesarios </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Resumen de la base de datos a obtener\n",
    "</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Tres categorías de cafeteras</p>\n",
    "<ul>\n",
    "    <li style=\"font-size: 18px;\" class=\"list-item\">Cafeteras de goteo</li>\n",
    "    <li style=\"font-size: 18px;\" class=\"list-item\">Cafeteras automáticas</li>\n",
    "    <li style=\"font-size: 18px;\" class=\"list-item\">Cafeteras individuales</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Cada máquina tiene su página de base, así como su correspondiente sección de reseñas</p>\n",
    "<p style=\"font-size: 18px; margin-top: -20px;\">Las reseñas de cada máquina se almacenarán por separado, como se muestra en el esquema siguiente</p>\n",
    "\n",
    "---\n",
    "\n",
    "![Diagram](assets/Scheme_light_final.png)\n",
    "\n",
    "---\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Formando base.csv\n",
    "</b>\n",
    "\n",
    "```python\n",
    "dataframe = {\n",
    "    'ID': ['0', '1', '2'],\n",
    "    'category': ['Cafeteras de goteo', 'Cafeteras automaticas', 'Cafeteras individuales'],\n",
    "    'category_url': [\n",
    "        'https://www.amazon.es/s?i=kitchen&rh=n%3A2165180031&fs=true&page=1&qid=1721224661&ref=sr_pg_2',\n",
    "        'https://www.amazon.es/s?i=kitchen&rh=n%3A2165187031&fs=true&page=1&qid=1721228721&ref=sr_pg_2',\n",
    "        'https://www.amazon.es/s?i=kitchen&rh=n%3A2165185031&fs=true&page=1&qid=1721229794&ref=sr_pg_2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dataframe)\n",
    "df.to_csv('database/base.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "df.to_csv('database/0.csv')\n",
    "df.to_csv('database/1.csv')\n",
    "df.to_csv('database/2.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Interacción con la base de datos  \n",
    "</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Definición de funciones para facilitar la lectura y escritura de los datos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_0(goods_url, reviews_url, filename=f'database/0.csv'):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "    \n",
    "    next_id = os.path.join('', f'0-{len(df):06}')\n",
    "    \n",
    "    new_row = pd.DataFrame([{'ID': next_id, 'goods_url': goods_url, 'reviews_url': reviews_url}])\n",
    "    \n",
    "    if not df[(df['goods_url'] == goods_url) & (df['reviews_url'] == reviews_url)].empty:\n",
    "        print(f\"Duplicate row found. The row {goods_url} will not be added to {filename}.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Row {goods_url} added successfully to {filename}\")\n",
    "    \n",
    "def add_to_1(goods_url, reviews_url, filename=f'database/1.csv'):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "    \n",
    "    next_id = os.path.join('', f'1-{len(df):06}')\n",
    "    \n",
    "    new_row = pd.DataFrame([{'ID': next_id, 'goods_url': goods_url, 'reviews_url': reviews_url}])\n",
    "    \n",
    "    if not df[(df['goods_url'] == goods_url) & (df['reviews_url'] == reviews_url)].empty:\n",
    "        print(f\"Duplicate row found. The row {goods_url} will not be added to {filename}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Row {goods_url} added successfully to {filename}\")\n",
    "    \n",
    "def add_to_2(goods_url, reviews_url, filename=f'database/2.csv'):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "    \n",
    "    next_id = os.path.join('', f'2-{len(df):06}')\n",
    "    \n",
    "    new_row = pd.DataFrame([{'ID': next_id, 'goods_url': goods_url, 'reviews_url': reviews_url}])\n",
    "    \n",
    "    if not df[(df['goods_url'] == goods_url) & (df['reviews_url'] == reviews_url)].empty:\n",
    "        print(f\"Duplicate row found. The row {goods_url} will not be added to {filename}.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Row {goods_url} added successfully to {filename}\")\n",
    "\n",
    "def get_reviews_url_by_index(index, filename): # obtener de la cadena urls de las reseñas por ID\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    index = index.split('-')[1]\n",
    "    index = int(index)\n",
    "    \n",
    "    if index < 0 or index >= len(df):\n",
    "        raise IndexError(\"ID out of range of DataFrame\")\n",
    "    \n",
    "    reviews_url = df.loc[index, 'reviews_url']\n",
    "    \n",
    "    return reviews_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Recopilación y almacenamiento de URL de destino para cada categoría respectiva\n",
    "</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Para raspar las reseñas de productos, tenemos que reunir las URL de productos de interés.</p>\n",
    "<p style=\"font-size: 18px;  margin-top: -20px;\">En caso de hacelo automáticamente, esto conllevaría demasiados productos irrelevantes de todas las categorías, como accesorios o máquinas sin reseñas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=sr_1_5?dib=eyJ2IjoiMSJ9.hm_0gtZLV81iXXXtKmlJBukw1-YLVxl46pozcPTCJEZRyZspar_iwpBR3EVyK5U8HLvWZz3Qmtn8mB3LBO54S8ed-v54It4Uk4xz0w48XkLhIlGEKueoOlq4M-5PRtZuG4BUO8duJHKCxbHdmDp_GfYGniiZBw0DXFanlSBtrWiqW7oCEcTk8JvUrmRftutsXPTxOuuvYaDfE7la4mP84ffjke69eou__qOxUIFkWUbhw0xmxPv6zS837XSYanX71v1dlqenmNc8QK8WLuBsTxt32e0twlbyWWCYniU3uxo.vU_YhbI33x6j3-eUUiyH5BehdoVNq9NU-U5zwwUA3DM&dib_tag=se&qid=1723372286&s=kitchen&sr=1-5 added successfully to database/1.csv\n"
     ]
    }
   ],
   "source": [
    "add_to_1('https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=sr_1_5?dib=eyJ2IjoiMSJ9.hm_0gtZLV81iXXXtKmlJBukw1-YLVxl46pozcPTCJEZRyZspar_iwpBR3EVyK5U8HLvWZz3Qmtn8mB3LBO54S8ed-v54It4Uk4xz0w48XkLhIlGEKueoOlq4M-5PRtZuG4BUO8duJHKCxbHdmDp_GfYGniiZBw0DXFanlSBtrWiqW7oCEcTk8JvUrmRftutsXPTxOuuvYaDfE7la4mP84ffjke69eou__qOxUIFkWUbhw0xmxPv6zS837XSYanX71v1dlqenmNc8QK8WLuBsTxt32e0twlbyWWCYniU3uxo.vU_YhbI33x6j3-eUUiyH5BehdoVNq9NU-U5zwwUA3DM&dib_tag=se&qid=1723372286&s=kitchen&sr=1-5', 'https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/product-reviews/B0CDCFH17J/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate row found. The row https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=pd_vtp_d_sccl_3_6/262-2739010-6039420?pd_rd_w=YSns8&content-id=amzn1.sym.79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_p=79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_r=EZBGN1Y8NJ7KGCWMN1SD&pd_rd_wg=CWYHE&pd_rd_r=f80789ca-030a-4a52-a3be-13ba5704a3a6&pd_rd_i=B0CDCFH17J&th=1 will not be added to database/1.csv\n"
     ]
    }
   ],
   "source": [
    "add_to_1('https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=pd_vtp_d_sccl_3_6/262-2739010-6039420?pd_rd_w=YSns8&content-id=amzn1.sym.79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_p=79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_r=EZBGN1Y8NJ7KGCWMN1SD&pd_rd_wg=CWYHE&pd_rd_r=f80789ca-030a-4a52-a3be-13ba5704a3a6&pd_rd_i=B0CDCFH17J&th=1', 'https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/product-reviews/B0CDCFH17J/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<b style=\"font-size: 20px;\">Especificación de las URLs</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\"> Amazon.es limita la cantidad de opiniones de productos accesibles al público a 100 por artículo.</p>\n",
    "<p style=\"font-size: 18px; margin-top: -20px;\">Para obtener más datos hay que aplicar filtros. Eso podría ayudar a descargar más reseñas.</p>\n",
    "\n",
    "<p style=\"font-size: 18px;\">El mismo método puede aplicarse a otros productos de amazon.es</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(ID, filename):\n",
    "    \n",
    "    try:\n",
    "        base_url = get_reviews_url_by_index(ID, filename)\n",
    "        print(f\"The reviews_url at index {ID} is: {base_url}\")\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "    \n",
    "    filters = [\n",
    "        'sortBy=recent',\n",
    "        'sortBy=helpful',\n",
    "        'sortBy=rating',\n",
    "        'filterByStar=one_star',\n",
    "        'filterByStar=two_star',\n",
    "        'filterByStar=three_star',\n",
    "        'filterByStar=four_star',\n",
    "        'filterByStar=five_star'\n",
    "    ]\n",
    "    \n",
    "    list_urls = []\n",
    "    for filter_option in filters:\n",
    "        for page in range(1, 11):\n",
    "            \n",
    "            #actualizar el filtro y el número de página  \n",
    "            updated_url = f\"{base_url}&{filter_option}&pageNumber={page}\"\n",
    "            list_urls.append(updated_url)\n",
    "    \n",
    "    return list_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b style=\"font-size: 20px;\">Interacción automática con servicios web</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Selenium WebDriver es una herramienta que proporciona una interfaz para interactuar con los navegadores web.</p>\n",
    "\n",
    "```python\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<b style=\"font-size: 20px;\">Ajustes necesarios para el bot</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Antes de utilizar WebDriver tenemos que realizar algunos ajustes. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions() # ChromeOptions object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px;\">Para evitar sanciones, el bot debe emular el comportamiento de un usuario humano.</p>\n",
    "\n",
    "<p style=\"font-size: 18px; margin-top: -20px;\">Esta configuración permite al bot enviar una cadena de agente de usuario con las especificaciones del navegador, igual que haría un humano.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px; margin-top: -20px\"><b> No olvidar de introducir la ruta absoluta a cromedriver.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.add_argument('--headless')\n",
    "\n",
    "DRIVER_PATH = '/Users/apple/Downloads/Project_Inna/assets/chromedriver' # Introducir la ruta absoluta a su chromedriver\n",
    "service = Service(DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<p style=\"text-align: center; font-size: 25px; margin-top: 20px;\">\n",
    "    <strong>\n",
    "          Código final de scraper\n",
    "    </strong>\n",
    "</p>\n",
    "\n",
    "---\n",
    "<p style=\"font-size: 18px;\">Recopilación de opiniones de los 5 últimos artículos de la categoría Cafeteras individuales como ejemplo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reviews_url at index 2-000143 is: https://www.amazon.es/Bosch-TAS6502-Cafetera-c%C3%A1psulas-litros/product-reviews/B0857Z91PY/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:31<00:00,  1.90s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 143 is done\n",
      "Saved 289 individual reviews in database/reviews/2-000143.csv\n",
      "\n",
      "The reviews_url at index 2-000144 is: https://www.amazon.es/multibebida-TAS1003-OneTouch-individual-INTELLIBREW/product-reviews/B07GQKR88T/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:38<00:00,  1.98s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 144 is done\n",
      "Saved 501 individual reviews in database/reviews/2-000144.csv\n",
      "\n",
      "The reviews_url at index 2-000145 is: https://www.amazon.es/Bosch-TAS1107-Tassimo-Style-totalmente/product-reviews/B08D9NRCZ5/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:23<00:00,  1.79s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 145 is done\n",
      "Saved 136 individual reviews in database/reviews/2-000145.csv\n",
      "\n",
      "The reviews_url at index 2-000146 is: https://www.amazon.es/Krups-Nespresso-YY1531FD-Independiente-c%C3%A1psulas/product-reviews/B00IRWKB70/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:51<00:00,  2.15s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 146 is done\n",
      "Saved 467 individual reviews in database/reviews/2-000146.csv\n",
      "\n",
      "The reviews_url at index 2-000147 is: https://www.amazon.es/Philips-Cafetera-Compatible-Individual-degustaci%C3%B3n/product-reviews/B087G85L13/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:38<00:00,  1.98s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 147 is done\n",
      "Saved 501 individual reviews in database/reviews/2-000147.csv\n",
      "\n",
      "--------------------------------------------------\n",
      "Time taken: 0:13:07.671734\n"
     ]
    }
   ],
   "source": [
    "def scrape_reviews(urls):\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for url in tqdm(urls, desc='Processing URLs', unit='URL'): \n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(1) # Tiempo de espera a cargarse la página web\n",
    "\n",
    "        # Descargar reseñas \n",
    "        review_blocks = driver.find_elements(By.CSS_SELECTOR, '.a-section.review')\n",
    "        for review_block in review_blocks:\n",
    "            title = review_block.find_element(By.CSS_SELECTOR, '.review-title-content').text.strip()\n",
    "            rating = review_block.find_element(By.CSS_SELECTOR, '.a-icon-alt').get_attribute('textContent').strip()\n",
    "            body = review_block.find_element(By.CSS_SELECTOR, '[data-hook=\"review-body\"]').text.strip()\n",
    "            author = review_block.find_element(By.CSS_SELECTOR, '.a-profile-name').text.strip()\n",
    "            date = review_block.find_element(By.CSS_SELECTOR, '.review-date').text.strip()\n",
    "\n",
    "            reviews.append({\n",
    "                'title': title,\n",
    "                'rating': rating,\n",
    "                'body': body,\n",
    "                'author': author,\n",
    "                'date': date,\n",
    "            })\n",
    "    \n",
    "    driver.quit()\n",
    "    return reviews\n",
    "\n",
    "# Eliminar duplicados y cuardar los datos\n",
    "def save_to_csv(reviews, filename):\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.drop_duplicates(subset=['title', 'body', 'author'], inplace=True)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    return int(df.shape[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    start_time = time.perf_counter() \n",
    "\n",
    "    for i in range(143, 148): # rango ID\n",
    "        \n",
    "        ID = f'2-{i:06}'\n",
    "    \n",
    "        urls = get_urls(ID, f'database/2.csv')\n",
    "        \n",
    "        reviews = scrape_reviews(urls)\n",
    "        print(f\"Parsing item {i} is done\")\n",
    "    \n",
    "        adress = f'database/reviews/2-{i:06}.csv'\n",
    "        l = save_to_csv(reviews, adress)\n",
    "        print(f'Saved {l} individual reviews in database/reviews/{ID}.csv\\n')\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('-'*50 + f'\\nTime taken: {str(datetime.timedelta(seconds = elapsed_time))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b style=\"font-size: 20px;\">Demostración de los datos descargados</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 72509 reviews in Cafeteras de goteo category.\n",
      "Scraped 35330 reviews in Cafeteras automaticas category.\n",
      "Scraped 42625 reviews in Cafeteras individuales category.\n",
      "--------------------------------------------------\n",
      "Total number of reviews in the database: 150464\n",
      "--------------------------------------------------\n",
      "Estimated total time taken: 20:16:15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regalo</td>\n",
       "      <td>5,0 de 5 estrellas</td>\n",
       "      <td>Me gustó mucho</td>\n",
       "      <td>Cliente Amazon</td>\n",
       "      <td>Revisado en España el 6 de abril de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No ha durado ni la garantía + pésimo servicio ...</td>\n",
       "      <td>1,0 de 5 estrellas</td>\n",
       "      <td>Ni los 24 meses de garantía ha durado, y al en...</td>\n",
       "      <td>MaX</td>\n",
       "      <td>Revisado en España el 3 de abril de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Está bien</td>\n",
       "      <td>3,0 de 5 estrellas</td>\n",
       "      <td>Después de más de dos meses usándola hace muy ...</td>\n",
       "      <td>Lorena</td>\n",
       "      <td>Revisado en España el 14 de marzo de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfecta!</td>\n",
       "      <td>5,0 de 5 estrellas</td>\n",
       "      <td>Me encanta! Soy adicta al café y me gusta toma...</td>\n",
       "      <td>Perfecta!</td>\n",
       "      <td>Revisado en España el 22 de febrero de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXCELENTE</td>\n",
       "      <td>5,0 de 5 estrellas</td>\n",
       "      <td>como única pega que limpiar el palito del vapo...</td>\n",
       "      <td>Sil at</td>\n",
       "      <td>Revisado en España el 20 de febrero de 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              rating  \\\n",
       "0                                             Regalo  5,0 de 5 estrellas   \n",
       "1  No ha durado ni la garantía + pésimo servicio ...  1,0 de 5 estrellas   \n",
       "2                                          Está bien  3,0 de 5 estrellas   \n",
       "3                                          Perfecta!  5,0 de 5 estrellas   \n",
       "4                                          EXCELENTE  5,0 de 5 estrellas   \n",
       "\n",
       "                                                body          author  \\\n",
       "0                                     Me gustó mucho  Cliente Amazon   \n",
       "1  Ni los 24 meses de garantía ha durado, y al en...             MaX   \n",
       "2  Después de más de dos meses usándola hace muy ...          Lorena   \n",
       "3  Me encanta! Soy adicta al café y me gusta toma...       Perfecta!   \n",
       "4  como única pega que limpiar el palito del vapo...          Sil at   \n",
       "\n",
       "                                          date  \n",
       "0     Revisado en España el 6 de abril de 2024  \n",
       "1     Revisado en España el 3 de abril de 2024  \n",
       "2    Revisado en España el 14 de marzo de 2024  \n",
       "3  Revisado en España el 22 de febrero de 2024  \n",
       "4  Revisado en España el 20 de febrero de 2024  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.read_csv('database/base.csv')\n",
    "all_reviews = pd.DataFrame()\n",
    "c = 0 # número de productos\n",
    "\n",
    "for ID in base_df['ID']:\n",
    "    id_df = pd.read_csv(f'database/{ID}.csv')\n",
    "    category = base_df.loc[base_df['ID'] == ID, 'category'].values\n",
    "    \n",
    "    reviews_df = pd.DataFrame()\n",
    "    \n",
    "    for local_id in id_df['ID']:\n",
    "        review_file = f'database/reviews/{local_id}.csv'\n",
    "        c+=1\n",
    "        \n",
    "        if os.path.exists(review_file):\n",
    "            review_df = pd.read_csv(review_file)\n",
    "            reviews_df = pd.concat([reviews_df, review_df], ignore_index=True)\n",
    "    \n",
    "    print(f'Scraped {len(reviews_df)} reviews in {category[0]} category.')\n",
    "\n",
    "    all_reviews = pd.concat([all_reviews, reviews_df], ignore_index=True)\n",
    "\n",
    "print('-'*50 + f'\\nTotal number of reviews in the database: {len(all_reviews)}\\n' + '-'*50)\n",
    "\n",
    "average_time = 139 #calculado en función de los intentos anteriores\n",
    "print(f'Estimated total time taken: {str(datetime.timedelta(seconds = average_time * c))}')\n",
    "\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
