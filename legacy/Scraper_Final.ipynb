{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 30px;\">\n",
    "    <strong>\n",
    "          Scraper for Amazon.es\n",
    "    </strong>\n",
    "</p>\n",
    "\n",
    "----\n",
    "\n",
    "<b style=\"text-align: left; font-size: 18px;\">\n",
    "    The following project is specifically designed to scrape publicly available data concerning user reviews for goods listed on amazon.es\n",
    "</b>\n",
    "\n",
    "----\n",
    "\n",
    "<b style=\"font-size: 20px;\">Project Roadmap</b>\n",
    "\n",
    "-  <p style=\"font-size: 18px;\">Create a list of target URLs</p>\n",
    "-  <p style=\"font-size: 18px;\">Develop a program to automatically access specified websites and extract their data</p>\n",
    "-  <p style=\"font-size: 18px;\">Save the acquired data in a Database for future applications</p>\n",
    "---\n",
    "\n",
    "<b style=\"font-size: 20px;\">Required tools</b>\n",
    "\n",
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    <a href=\"https://www.python.org/downloads/\" target=\"_blank\" rel=\"noopener noreferrer\">Latest version of Python</a>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    <a href=\"https://googlechromelabs.github.io/chrome-for-testing/\" target=\"_blank\" rel=\"noopener noreferrer\">Latest version of WebDriver</a>\n",
    "</blockquote>\n",
    "\n",
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    Selenuim library for scraping purposes\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    Pandas library for data storage and manipulation\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote style=\"background-color: #f0f0f0; padding: 10px; border-left: 10px solid #3498db; font-size: 18px;\">\n",
    "    TQDM library for progress check \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b style=\"font-size: 20px;\">Importing necessary libraries </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Database outlook\n",
    "</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Our project requires data concerning coffee machines. They can by subdivided into 3 major groups:</p>\n",
    "<ul>\n",
    "    <li style=\"font-size: 18px;\" class=\"list-item\">Cafeteras de goteo</li>\n",
    "    <li style=\"font-size: 18px;\" class=\"list-item\">Cafeteras automáticas</li>\n",
    "    <li style=\"font-size: 18px;\" class=\"list-item\">Cafeteras individuales</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Each machine has its base page as well as a respective review section.</p>\n",
    "<p style=\"font-size: 18px; margin-top: -20px;\">Reviews for each machine will be stored separately, as show in the scheme below.</p>\n",
    "\n",
    "---\n",
    "\n",
    "![Diagram](assets/Scheme_light_final.png)\n",
    "\n",
    "---\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Forming the base.csv\n",
    "</b>\n",
    "\n",
    "```python\n",
    "dataframe = {\n",
    "    'ID': ['0', '1', '2'],\n",
    "    'category': ['Cafeteras de goteo', 'Cafeteras automaticas', 'Cafeteras individuales'],\n",
    "    'category_url': [\n",
    "        'https://www.amazon.es/s?i=kitchen&rh=n%3A2165180031&fs=true&page=1&qid=1721224661&ref=sr_pg_2',\n",
    "        'https://www.amazon.es/s?i=kitchen&rh=n%3A2165187031&fs=true&page=1&qid=1721228721&ref=sr_pg_2',\n",
    "        'https://www.amazon.es/s?i=kitchen&rh=n%3A2165185031&fs=true&page=1&qid=1721229794&ref=sr_pg_2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dataframe)\n",
    "df.to_csv('database/base.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "df.to_csv('database/0.csv')\n",
    "df.to_csv('database/1.csv')\n",
    "df.to_csv('database/2.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Database interaction \n",
    "</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Defining functions for easy reading and writing of the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_0(goods_url, reviews_url, filename=f'database/0.csv'):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "    \n",
    "    next_id = os.path.join('', f'0-{len(df):06}')\n",
    "    \n",
    "    new_row = pd.DataFrame([{'ID': next_id, 'goods_url': goods_url, 'reviews_url': reviews_url}])\n",
    "    \n",
    "    if not df[(df['goods_url'] == goods_url) & (df['reviews_url'] == reviews_url)].empty:\n",
    "        print(f\"Duplicate row found. The row {goods_url} will not be added to {filename}.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Row {goods_url} added successfully to {filename}\")\n",
    "    \n",
    "def add_to_1(goods_url, reviews_url, filename=f'database/1.csv'):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "    \n",
    "    next_id = os.path.join('', f'1-{len(df):06}')\n",
    "    \n",
    "    new_row = pd.DataFrame([{'ID': next_id, 'goods_url': goods_url, 'reviews_url': reviews_url}])\n",
    "    \n",
    "    if not df[(df['goods_url'] == goods_url) & (df['reviews_url'] == reviews_url)].empty:\n",
    "        print(f\"Duplicate row found. The row {goods_url} will not be added to {filename}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Row {goods_url} added successfully to {filename}\")\n",
    "    \n",
    "def add_to_2(goods_url, reviews_url, filename=f'database/2.csv'):\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['ID', 'goods_url', 'reviews_url'])\n",
    "    \n",
    "    next_id = os.path.join('', f'2-{len(df):06}')\n",
    "    \n",
    "    new_row = pd.DataFrame([{'ID': next_id, 'goods_url': goods_url, 'reviews_url': reviews_url}])\n",
    "    \n",
    "    if not df[(df['goods_url'] == goods_url) & (df['reviews_url'] == reviews_url)].empty:\n",
    "        print(f\"Duplicate row found. The row {goods_url} will not be added to {filename}.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Row {goods_url} added successfully to {filename}\")\n",
    "\n",
    "def get_reviews_url_by_index(index, filename): # getting reviews url string by ID\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    index = index.split('-')[1]\n",
    "    index = int(index)\n",
    "    \n",
    "    if index < 0 or index >= len(df):\n",
    "        raise IndexError(\"ID out of range of DataFrame\")\n",
    "    \n",
    "    reviews_url = df.loc[index, 'reviews_url']\n",
    "    \n",
    "    return reviews_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b style=\"font-size: 20px;\">\n",
    "    Gathering and saving target URLs for each respective category\n",
    "</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">In order to scrape the product reviews, we have to gather product URLs of interest.</p>\n",
    "<p style=\"font-size: 18px;  margin-top: -20px;\">Doing that automatically would bring in too much irrelevant goods from every category, like acessories or machines without reviews.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=sr_1_5?dib=eyJ2IjoiMSJ9.hm_0gtZLV81iXXXtKmlJBukw1-YLVxl46pozcPTCJEZRyZspar_iwpBR3EVyK5U8HLvWZz3Qmtn8mB3LBO54S8ed-v54It4Uk4xz0w48XkLhIlGEKueoOlq4M-5PRtZuG4BUO8duJHKCxbHdmDp_GfYGniiZBw0DXFanlSBtrWiqW7oCEcTk8JvUrmRftutsXPTxOuuvYaDfE7la4mP84ffjke69eou__qOxUIFkWUbhw0xmxPv6zS837XSYanX71v1dlqenmNc8QK8WLuBsTxt32e0twlbyWWCYniU3uxo.vU_YhbI33x6j3-eUUiyH5BehdoVNq9NU-U5zwwUA3DM&dib_tag=se&qid=1723372286&s=kitchen&sr=1-5 added successfully to database/1.csv\n"
     ]
    }
   ],
   "source": [
    "add_to_1('https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=sr_1_5?dib=eyJ2IjoiMSJ9.hm_0gtZLV81iXXXtKmlJBukw1-YLVxl46pozcPTCJEZRyZspar_iwpBR3EVyK5U8HLvWZz3Qmtn8mB3LBO54S8ed-v54It4Uk4xz0w48XkLhIlGEKueoOlq4M-5PRtZuG4BUO8duJHKCxbHdmDp_GfYGniiZBw0DXFanlSBtrWiqW7oCEcTk8JvUrmRftutsXPTxOuuvYaDfE7la4mP84ffjke69eou__qOxUIFkWUbhw0xmxPv6zS837XSYanX71v1dlqenmNc8QK8WLuBsTxt32e0twlbyWWCYniU3uxo.vU_YhbI33x6j3-eUUiyH5BehdoVNq9NU-U5zwwUA3DM&dib_tag=se&qid=1723372286&s=kitchen&sr=1-5', 'https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/product-reviews/B0CDCFH17J/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate row found. The row https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=pd_vtp_d_sccl_3_6/262-2739010-6039420?pd_rd_w=YSns8&content-id=amzn1.sym.79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_p=79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_r=EZBGN1Y8NJ7KGCWMN1SD&pd_rd_wg=CWYHE&pd_rd_r=f80789ca-030a-4a52-a3be-13ba5704a3a6&pd_rd_i=B0CDCFH17J&th=1 will not be added to database/1.csv\n"
     ]
    }
   ],
   "source": [
    "add_to_1('https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/dp/B0CDCFH17J/ref=pd_vtp_d_sccl_3_6/262-2739010-6039420?pd_rd_w=YSns8&content-id=amzn1.sym.79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_p=79bfeeec-d048-49eb-a46d-fd0df43d59bb&pf_rd_r=EZBGN1Y8NJ7KGCWMN1SD&pd_rd_wg=CWYHE&pd_rd_r=f80789ca-030a-4a52-a3be-13ba5704a3a6&pd_rd_i=B0CDCFH17J&th=1', 'https://www.amazon.es/Philips-Serie-3300-Cafetera-Superautom%C3%A1tica/product-reviews/B0CDCFH17J/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<b style=\"font-size: 20px;\">Specification of the target URLs</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\"> Amazon.es limits the amount of publicly accessible product reviews to 100 per item.</p>\n",
    "<p style=\"font-size: 18px; margin-top: -20px;\">In order to possibly scrape more data one has to apply filters. That could potentially disclose more reviews.</p>\n",
    "\n",
    "<p style=\"font-size: 18px;\">The same method can be applied to other goods on amazon.es.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(ID, filename):\n",
    "    \n",
    "    try:\n",
    "        base_url = get_reviews_url_by_index(ID, filename)\n",
    "        print(f\"The reviews_url at index {ID} is: {base_url}\")\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "    \n",
    "    filters = [\n",
    "        'sortBy=recent',\n",
    "        'sortBy=helpful',\n",
    "        'sortBy=rating',\n",
    "        'filterByStar=one_star',\n",
    "        'filterByStar=two_star',\n",
    "        'filterByStar=three_star',\n",
    "        'filterByStar=four_star',\n",
    "        'filterByStar=five_star'\n",
    "    ]\n",
    "    \n",
    "    list_urls = []\n",
    "    for filter_option in filters:\n",
    "        for page in range(1, 11):\n",
    "            \n",
    "            #updating the filter and page number \n",
    "            updated_url = f\"{base_url}&{filter_option}&pageNumber={page}\"\n",
    "            list_urls.append(updated_url)\n",
    "    \n",
    "    return list_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b style=\"font-size: 20px;\">Automatic interaction with web services</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Selenium WebDriver is a tool that provides a programmatic interface for interacting with web browsers.</p>\n",
    "\n",
    "```python\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<b style=\"font-size: 20px;\">Necessary adgustments for the bot</b>\n",
    "\n",
    "<p style=\"font-size: 18px;\">Before using WebDriver we have to add a few tweaks. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions() # making a ChromeOptions object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px;\">To avoid sanctions the bot must emulate the behaviour of a human user.</p>\n",
    "\n",
    "<p style=\"font-size: 18px; margin-top: -20px;\">This setting allows the bot to send a user-agent string with browser specs, just like a human would.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px;\">Turn off Chrome UI and prepare to start the driver. Don't forget to enter the absolute path to your chromedriver.</p>\n",
    "<p style=\"font-size: 18px; margin-top: -20px\"><b>Don't forget to enter the absolute path to your chromedriver!</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.add_argument('--headless')\n",
    "\n",
    "DRIVER_PATH = '/Users/apple/Downloads/Project_Gnomi_Huekradi/assets/chromedriver' # Enter the absolute path to your chromedriver\n",
    "service = Service(DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<p style=\"text-align: center; font-size: 25px; margin-top: 20px;\">\n",
    "    <strong>\n",
    "          The Final code for scraping\n",
    "    </strong>\n",
    "</p>\n",
    "\n",
    "---\n",
    "<p style=\"font-size: 18px;\">Scraping reviews for last 10 items in Cafeteras individuales category as an example.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reviews_url at index 2-000137 is: https://www.amazon.es/Nescaf%C3%A9-Dolce-Gusto-KP1A3BKA-capacidad/product-reviews/B08HSJY2JT/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:35<00:00,  1.94s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 137 is done\n",
      "Saved 370 individual reviews in database/reviews/2-000137.csv\n",
      "\n",
      "The reviews_url at index 2-000138 is: https://www.amazon.es/Cafetera-c%C3%A1psulas-capacidad-calientes-Thermoblock/product-reviews/B0CK8B5PPZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:30<00:00,  1.88s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 138 is done\n",
      "Saved 500 individual reviews in database/reviews/2-000138.csv\n",
      "\n",
      "The reviews_url at index 2-000139 is: https://www.amazon.es/Nespresso-DeLonghi-Inissia-EN-80-B/product-reviews/B00G5YOVZA/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:52<00:00,  2.16s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 139 is done\n",
      "Saved 501 individual reviews in database/reviews/2-000139.csv\n",
      "\n",
      "The reviews_url at index 2-000140 is: https://www.amazon.es/BOSCH-Cafetera-Tassimo-TAS1002NV-Happy/product-reviews/B0CMTL4PB3/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [01:56<00:00,  1.46s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 140 is done\n",
      "Saved 13 individual reviews in database/reviews/2-000140.csv\n",
      "\n",
      "The reviews_url at index 2-000141 is: https://www.amazon.es/Nescaf%C3%A9-Dolce-Gusto-KP1A3BKA-capacidad/product-reviews/B08HSJY2JT/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:33<00:00,  1.92s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 141 is done\n",
      "Saved 371 individual reviews in database/reviews/2-000141.csv\n",
      "\n",
      "The reviews_url at index 2-000142 is: https://www.amazon.es/Bosch-TAS1002N-Tassimo-Happy/product-reviews/B09CT39KZG/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:41<00:00,  2.02s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 142 is done\n",
      "Saved 500 individual reviews in database/reviews/2-000142.csv\n",
      "\n",
      "The reviews_url at index 2-000143 is: https://www.amazon.es/Bosch-TAS6502-Cafetera-c%C3%A1psulas-litros/product-reviews/B0857Z91PY/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|█████████████████████████| 80/80 [02:18<00:00,  1.73s/URL]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing item 143 is done\n",
      "Saved 289 individual reviews in database/reviews/2-000143.csv\n",
      "\n",
      "--------------------------------------------------\n",
      "Time taken: 0:17:34.324899\n"
     ]
    }
   ],
   "source": [
    "def scrape_reviews(urls):\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for url in tqdm(urls, desc='Processing URLs', unit='URL'): \n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(1) # Waiting for the page to load\n",
    "\n",
    "        # Getting reviews\n",
    "        review_blocks = driver.find_elements(By.CSS_SELECTOR, '.a-section.review')\n",
    "        for review_block in review_blocks:\n",
    "            title = review_block.find_element(By.CSS_SELECTOR, '.review-title-content').text.strip()\n",
    "            rating = review_block.find_element(By.CSS_SELECTOR, '.a-icon-alt').get_attribute('textContent').strip()\n",
    "            body = review_block.find_element(By.CSS_SELECTOR, '[data-hook=\"review-body\"]').text.strip()\n",
    "            author = review_block.find_element(By.CSS_SELECTOR, '.a-profile-name').text.strip()\n",
    "            date = review_block.find_element(By.CSS_SELECTOR, '.review-date').text.strip()\n",
    "\n",
    "            reviews.append({\n",
    "                'title': title,\n",
    "                'rating': rating,\n",
    "                'body': body,\n",
    "                'author': author,\n",
    "                'date': date,\n",
    "            })\n",
    "    \n",
    "    driver.quit()\n",
    "    return reviews\n",
    "\n",
    "# Removing duplicates and saving data\n",
    "def save_to_csv(reviews, filename):\n",
    "    df = pd.DataFrame(reviews)\n",
    "    df.drop_duplicates(subset=['title', 'body', 'author'], inplace=True)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    return int(df.shape[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    start_time = time.perf_counter() \n",
    "\n",
    "    for i in range(137, 144): #ID range\n",
    "        \n",
    "        ID = f'2-{i:06}'\n",
    "    \n",
    "        urls = get_urls(ID, f'database/2.csv')\n",
    "        \n",
    "        reviews = scrape_reviews(urls)\n",
    "        print(f\"Parsing item {i} is done\")\n",
    "    \n",
    "        adress = f'database/reviews/2-{i:06}.csv'\n",
    "        l = save_to_csv(reviews, adress)\n",
    "        print(f'Saved {l} individual reviews in database/reviews/{ID}.csv\\n')\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('-'*50 + f'\\nTime taken: {str(datetime.timedelta(seconds = elapsed_time))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b style=\"font-size: 20px;\">Demonstrating acquired data</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 72509 reviews in Cafeteras de goteo category.\n",
      "Scraped 35330 reviews in Cafeteras automaticas category.\n",
      "Scraped 42625 reviews in Cafeteras individuales category.\n",
      "--------------------------------------------------\n",
      "Total number of reviews in the database: 150464\n",
      "--------------------------------------------------\n",
      "Estimated total time taken: 20:16:15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regalo</td>\n",
       "      <td>5,0 de 5 estrellas</td>\n",
       "      <td>Me gustó mucho</td>\n",
       "      <td>Cliente Amazon</td>\n",
       "      <td>Revisado en España el 6 de abril de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No ha durado ni la garantía + pésimo servicio ...</td>\n",
       "      <td>1,0 de 5 estrellas</td>\n",
       "      <td>Ni los 24 meses de garantía ha durado, y al en...</td>\n",
       "      <td>MaX</td>\n",
       "      <td>Revisado en España el 3 de abril de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Está bien</td>\n",
       "      <td>3,0 de 5 estrellas</td>\n",
       "      <td>Después de más de dos meses usándola hace muy ...</td>\n",
       "      <td>Lorena</td>\n",
       "      <td>Revisado en España el 14 de marzo de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfecta!</td>\n",
       "      <td>5,0 de 5 estrellas</td>\n",
       "      <td>Me encanta! Soy adicta al café y me gusta toma...</td>\n",
       "      <td>Perfecta!</td>\n",
       "      <td>Revisado en España el 22 de febrero de 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXCELENTE</td>\n",
       "      <td>5,0 de 5 estrellas</td>\n",
       "      <td>como única pega que limpiar el palito del vapo...</td>\n",
       "      <td>Sil at</td>\n",
       "      <td>Revisado en España el 20 de febrero de 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              rating  \\\n",
       "0                                             Regalo  5,0 de 5 estrellas   \n",
       "1  No ha durado ni la garantía + pésimo servicio ...  1,0 de 5 estrellas   \n",
       "2                                          Está bien  3,0 de 5 estrellas   \n",
       "3                                          Perfecta!  5,0 de 5 estrellas   \n",
       "4                                          EXCELENTE  5,0 de 5 estrellas   \n",
       "\n",
       "                                                body          author  \\\n",
       "0                                     Me gustó mucho  Cliente Amazon   \n",
       "1  Ni los 24 meses de garantía ha durado, y al en...             MaX   \n",
       "2  Después de más de dos meses usándola hace muy ...          Lorena   \n",
       "3  Me encanta! Soy adicta al café y me gusta toma...       Perfecta!   \n",
       "4  como única pega que limpiar el palito del vapo...          Sil at   \n",
       "\n",
       "                                          date  \n",
       "0     Revisado en España el 6 de abril de 2024  \n",
       "1     Revisado en España el 3 de abril de 2024  \n",
       "2    Revisado en España el 14 de marzo de 2024  \n",
       "3  Revisado en España el 22 de febrero de 2024  \n",
       "4  Revisado en España el 20 de febrero de 2024  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.read_csv('database/base.csv')\n",
    "all_reviews = pd.DataFrame()\n",
    "c = 0 # number of goods\n",
    "\n",
    "for ID in base_df['ID']:\n",
    "    id_df = pd.read_csv(f'database/{ID}.csv')\n",
    "    category = base_df.loc[base_df['ID'] == ID, 'category'].values\n",
    "    \n",
    "    reviews_df = pd.DataFrame()\n",
    "    \n",
    "    for local_id in id_df['ID']:\n",
    "        review_file = f'database/reviews/{local_id}.csv'\n",
    "        c+=1\n",
    "        \n",
    "        if os.path.exists(review_file):\n",
    "            review_df = pd.read_csv(review_file)\n",
    "            reviews_df = pd.concat([reviews_df, review_df], ignore_index=True)\n",
    "    \n",
    "    print(f'Scraped {len(reviews_df)} reviews in {category[0]} category.')\n",
    "\n",
    "    all_reviews = pd.concat([all_reviews, reviews_df], ignore_index=True)\n",
    "\n",
    "print('-'*50 + f'\\nTotal number of reviews in the database: {len(all_reviews)}\\n' + '-'*50)\n",
    "\n",
    "average_time = 139 #calculated based on previous attempts\n",
    "print(f'Estimated total time taken: {str(datetime.timedelta(seconds = average_time * c))}')\n",
    "\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
